{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89d58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added c:\\Users\\asus\\OneDrive\\Desktop\\projects\\house_price_prediction to sys.path for module import.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to sys.path for module import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476b44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d1c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import load_and_initial_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d994226",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/AmesHousing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd32fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns standardized using a robust method in data_loader.py.\n",
      "Dropped 'order' column.\n",
      "Dropped 'pid' column.\n",
      "Data loaded and initially cleaned. Shape: (2930, 80)\n",
      "data loaded and cleaned initially using data_loader.py\n"
     ]
    }
   ],
   "source": [
    "df = load_and_initial_clean(DATA_PATH)\n",
    "if df is None:\n",
    "    exit()\n",
    "print(\"data loaded and cleaned initially using data_loader.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e601d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['saleprice']\n",
    "X = df.drop('saleprice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e0730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable 'saleprice' log-transformed to 'y_log'\n"
     ]
    }
   ],
   "source": [
    "y_log = np.log1p(y)\n",
    "print(\"target variable 'saleprice' log-transformed to 'y_log'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2713fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a37d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'house_age' and dropped 'year_built'.\n"
     ]
    }
   ],
   "source": [
    "current_year = X_processed['yr_sold'].max() # Use max year sold for consistency\n",
    "if 'year_built' in X_processed.columns:\n",
    "    X_processed['house_age'] = current_year - X_processed['year_built']\n",
    "    X_processed.drop('year_built', axis=1, inplace=True)\n",
    "    print(\"Created 'house_age' and dropped 'year_built'.\")\n",
    "elif 'yr_built' in X_processed.columns: # Fallback if original column was 'yr_built'\n",
    "    X_processed['house_age'] = current_year - X_processed['yr_built']\n",
    "    X_processed.drop('yr_built', axis=1, inplace=True)\n",
    "    print(\"Created 'house_age' and dropped 'yr_built'.\")\n",
    "else:\n",
    "    print(\"Warning: 'year_built' or 'yr_built' not found for 'house_age' creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99d1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created interaction term: 'overall_qual_gr_liv_area_inter'.\n"
     ]
    }
   ],
   "source": [
    "gr_liv_area_col = 'gr_liv_area_log' if 'gr_liv_area_log' in X_processed.columns else 'gr_liv_area'\n",
    "if 'overall_qual' in X_processed.columns and gr_liv_area_col in X_processed.columns:\n",
    "    X_processed['overall_qual_gr_liv_area_inter'] = X_processed['overall_qual'] * X_processed[gr_liv_area_col]\n",
    "    print(f\"Created interaction term: 'overall_qual_gr_liv_area_inter'.\")\n",
    "else:\n",
    "    print(\"Warning: Could not create interaction term (missing 'overall_qual' or 'gr_liv_area').\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c30dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created combined floor area: 'total_flr_sf_combined'.\n"
     ]
    }
   ],
   "source": [
    "total_bsmt_sf_col = 'total_bsmt_sf_log' if 'total_bsmt_sf_log' in X_processed.columns else 'total_bsmt_sf'\n",
    "first_flr_sf_col = '1st_flr_sf_log' if '1st_flr_sf_log' in X_processed.columns else '1st_flr_sf'\n",
    "\n",
    "if total_bsmt_sf_col in X_processed.columns and first_flr_sf_col in X_processed.columns:\n",
    "    X_processed['total_flr_sf_combined'] = X_processed[total_bsmt_sf_col] + X_processed[first_flr_sf_col]\n",
    "    print(\"Created combined floor area: 'total_flr_sf_combined'.\")\n",
    "else:\n",
    "    print(\"Warning: Could not create 'total_flr_sf_combined' (missing basement or 1st floor SF).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfb2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_initial = X_processed.select_dtypes(include=np.number).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c69463",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_candidates = [col for col in numerical_features_initial if col not in ['id', 'overall_qual', 'overall_cond', 'mo_sold', 'yr_sold', 'ms_subclass', 'pool_area', 'misc_val']] # Add more non-skewed numericals to this exclusion list if needed\n",
    "for feature in skewed_candidates:\n",
    "    if feature in X_processed.columns and X_processed[feature].skew() > 0.75:\n",
    "        if (X_processed[feature] >= 0).all(): # Ensure non-negative for log transform\n",
    "            X_processed[f'{feature}_log'] = np.log1p(X_processed[feature])\n",
    "            X_processed.drop(feature, axis=1, inplace=True)\n",
    "numerical_features_for_pipeline = X_processed.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features_for_pipeline = X_processed.select_dtypes(include='object').columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1ff6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_cols_impute_before_pipeline = [\n",
    "    'alley', 'bsmt_qual', 'bsmt_cond', 'bsmt_exposure', 'bsmtfin_type_1',\n",
    "    'bsmtfin_type_2', 'fireplace_qu', 'garage_type', 'garage_finish',\n",
    "    'garage_qual', 'garage_cond', 'pool_qc', 'fence', 'misc_feature', 'mas_vnr_type'\n",
    "]\n",
    "\n",
    "for col in none_cols_impute_before_pipeline:\n",
    "    if col in X_processed.columns and X_processed[col].isnull().any():\n",
    "        X_processed[col] = X_processed[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13659483",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_categories = {\n",
    "    'lot_shape': ['ir3', 'ir2', 'ir1', 'reg'],\n",
    "    'utilities': ['sev', 'no_sewr', 'no_pu', 'allpub'],\n",
    "    'land_slope': ['sev', 'mod', 'gtl'],\n",
    "    'exter_qual': ['po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'exter_cond': ['po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'bsmt_qual': ['none', 'po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'bsmt_cond': ['none', 'po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'bsmt_exposure': ['none', 'no', 'mn', 'av', 'gd'],\n",
    "    'bsmtfin_type_1': ['none', 'unf', 'lwq', 'rec', 'blq', 'alq', 'glq'],\n",
    "    'bsmtfin_type_2': ['none', 'unf', 'lwq', 'rec', 'blq', 'alq', 'glq'],\n",
    "    'heating_qc': ['po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'kitchen_qual': ['po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'functional': ['sal', 'sev', 'maj2', 'maj1', 'mod', 'min2', 'min1', 'typ'],\n",
    "    'fireplace_qu': ['none', 'po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'garage_finish': ['none', 'unf', 'rfn', 'fin'],\n",
    "    'garage_qual': ['none', 'po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'garage_cond': ['none', 'po', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'paved_drive': ['n', 'p', 'y'],\n",
    "    'pool_qc': ['none', 'fa', 'ta', 'gd', 'ex'],\n",
    "    'fence': ['none', 'mnww', 'gdprv', 'mnprv', 'gdpry'],\n",
    "    'ms_zoning': ['rh', 'rm', 'c(all)', 'fv', 'rl', 'a_agr', 'i(all)'],\n",
    "    'street': ['grvl', 'pave'],\n",
    "    'central_air': ['n', 'y']\n",
    "}\n",
    "numerical_cols_for_pipeline_input = X_processed.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols_for_pipeline_input = X_processed.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f19cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_nominal_features = [\n",
    "    'ms_subclass', 'bldg_type', 'house_style', 'roof_style', 'roof_matl',\n",
    "    'exterior_1st', 'exterior_2nd', 'foundation', 'electrical', 'sale_type',\n",
    "    'sale_condition'\n",
    "]\n",
    "\n",
    "# Ensure no overlap and all categorical_cols_for_pipeline_input are covered\n",
    "final_ordinal_features = [col for col in ordinal_categories.keys() if col in categorical_cols_for_pipeline_input]\n",
    "final_nominal_features = [col for col in categorical_cols_for_pipeline_input if col not in final_ordinal_features]\n",
    "\n",
    "# Dynamically prepare categories for OrdinalEncoder\n",
    "ordinal_encoder_categories_list = [ordinal_categories[f] for f in final_ordinal_features]\n",
    "\n",
    "\n",
    "# Numerical Pipeline: Impute remaining numerical NaNs with median, then scale\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessor (ColumnTransformer) built with numerical, ordinal, and nominal pipelines.\n"
     ]
    }
   ],
   "source": [
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')), # Ensures 'None' is handled if any new ones appear\n",
    "    ('ordinal', OrdinalEncoder(categories=ordinal_encoder_categories_list, handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Nominal Pipeline\n",
    "nominal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create the preprocessor combining all pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_cols_for_pipeline_input),\n",
    "        ('ord', ordinal_pipeline, final_ordinal_features),\n",
    "        ('nom', nominal_pipeline, final_nominal_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep any other unhandled columns (e.g., 'id' if not dropped)\n",
    ")\n",
    "print(\"\\nPreprocessor (ColumnTransformer) built with numerical, ordinal, and nominal pipelines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9509fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into training and testing sets.\n",
      "X_train shape: (2344, 81)\n",
      "y_train shape: (2344,)\n",
      "X_test shape: (586, 81)\n",
      "y_test shape: (586,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nData split into training and testing sets.\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9299c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
